{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30e49944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6dc6c6",
   "metadata": {},
   "source": [
    "### Download the Data and Perform a Control Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410e6d18",
   "metadata": {},
   "source": [
    "This code calculates the brightness (luminance) of each color and compares the average brightness by label\n",
    "(0 = dark, 1 = light).\n",
    "\n",
    "It checks whether colors labeled as light actually have higher brightness values than those labeled as dark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "054961b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIGHT_OR_DARK_FONT_IND\n",
      "0     81.349917\n",
      "1    187.567306\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/data_a2_mc1_vta_hs25.csv\", sep=\";\")\n",
    "lum = 0.2126*df.RED + 0.7152*df.GREEN + 0.0722*df.BLUE\n",
    "print(lum.groupby(df.LIGHT_OR_DARK_FONT_IND).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cb362dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"RED\", \"GREEN\", \"BLUE\"]].to_numpy(dtype=float) / 255.0  # scale RGB to [0,1]\n",
    "y = df[\"LIGHT_OR_DARK_FONT_IND\"].astype(int).to_numpy().reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1ce3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c71a981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple sequential model\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(3,)),          # 3 inputs: R, G, B\n",
    "    layers.Dense(4, activation='relu'),  # hidden layer with 4 neurons\n",
    "    layers.Dense(1, activation='sigmoid')  # output: 0 (dark) or 1 (light)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d1c3062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizers.SGD(learning_rate=0.1, momentum=0.0),  # <- SGD\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bace1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 0.9275 - loss: 0.1820 - val_accuracy: 0.9257 - val_loss: 0.1230\n",
      "Epoch 2/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - accuracy: 0.9498 - loss: 0.1009 - val_accuracy: 0.9665 - val_loss: 0.0755\n",
      "Epoch 3/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776us/step - accuracy: 0.9572 - loss: 0.0918 - val_accuracy: 0.9665 - val_loss: 0.0891\n",
      "Epoch 4/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 756us/step - accuracy: 0.9563 - loss: 0.0924 - val_accuracy: 0.9294 - val_loss: 0.1195\n",
      "Epoch 5/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 778us/step - accuracy: 0.9610 - loss: 0.0809 - val_accuracy: 0.9628 - val_loss: 0.0645\n",
      "Epoch 6/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.9647 - loss: 0.0665 - val_accuracy: 0.9926 - val_loss: 0.0377\n",
      "Epoch 7/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776us/step - accuracy: 0.9693 - loss: 0.0643 - val_accuracy: 0.9851 - val_loss: 0.0477\n",
      "Epoch 8/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step - accuracy: 0.9628 - loss: 0.0707 - val_accuracy: 0.9294 - val_loss: 0.1188\n",
      "Epoch 9/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - accuracy: 0.9712 - loss: 0.0624 - val_accuracy: 0.9740 - val_loss: 0.0654\n",
      "Epoch 10/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - accuracy: 0.9740 - loss: 0.0596 - val_accuracy: 0.9888 - val_loss: 0.0371\n",
      "Epoch 11/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776us/step - accuracy: 0.9740 - loss: 0.0525 - val_accuracy: 0.9814 - val_loss: 0.0435\n",
      "Epoch 12/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - accuracy: 0.9740 - loss: 0.0675 - val_accuracy: 0.9740 - val_loss: 0.0644\n",
      "Epoch 13/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 785us/step - accuracy: 0.9730 - loss: 0.0556 - val_accuracy: 0.9777 - val_loss: 0.0613\n",
      "Epoch 14/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 803us/step - accuracy: 0.9777 - loss: 0.0451 - val_accuracy: 0.9888 - val_loss: 0.0367\n",
      "Epoch 15/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 793us/step - accuracy: 0.9730 - loss: 0.0570 - val_accuracy: 0.9628 - val_loss: 0.0492\n",
      "Epoch 16/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - accuracy: 0.9777 - loss: 0.0475 - val_accuracy: 0.9665 - val_loss: 0.0631\n",
      "Epoch 17/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 777us/step - accuracy: 0.9730 - loss: 0.0550 - val_accuracy: 1.0000 - val_loss: 0.0282\n",
      "Epoch 18/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - accuracy: 0.9796 - loss: 0.0435 - val_accuracy: 0.9963 - val_loss: 0.0289\n",
      "Epoch 19/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.9805 - loss: 0.0466 - val_accuracy: 0.9257 - val_loss: 0.1628\n",
      "Epoch 20/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 789us/step - accuracy: 0.9749 - loss: 0.0501 - val_accuracy: 0.9442 - val_loss: 0.1168\n",
      "Epoch 21/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.9823 - loss: 0.0402 - val_accuracy: 0.9926 - val_loss: 0.0312\n",
      "Epoch 22/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.9777 - loss: 0.0471 - val_accuracy: 0.9963 - val_loss: 0.0232\n",
      "Epoch 23/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 812us/step - accuracy: 0.9777 - loss: 0.0487 - val_accuracy: 0.9926 - val_loss: 0.0253\n",
      "Epoch 24/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 796us/step - accuracy: 0.9805 - loss: 0.0473 - val_accuracy: 0.9926 - val_loss: 0.0248\n",
      "Epoch 25/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step - accuracy: 0.9768 - loss: 0.0506 - val_accuracy: 1.0000 - val_loss: 0.0206\n",
      "Epoch 26/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 799us/step - accuracy: 0.9777 - loss: 0.0488 - val_accuracy: 0.9814 - val_loss: 0.0466\n",
      "Epoch 27/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 955us/step - accuracy: 0.9777 - loss: 0.0514 - val_accuracy: 0.9926 - val_loss: 0.0278\n",
      "Epoch 28/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9814 - loss: 0.0412 - val_accuracy: 0.9814 - val_loss: 0.0349\n",
      "Epoch 29/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9814 - loss: 0.0421 - val_accuracy: 0.9628 - val_loss: 0.0499\n",
      "Epoch 30/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9851 - loss: 0.0353 - val_accuracy: 1.0000 - val_loss: 0.0208\n",
      "Epoch 31/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9814 - loss: 0.0441 - val_accuracy: 0.9665 - val_loss: 0.0567\n",
      "Epoch 32/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - accuracy: 0.9814 - loss: 0.0380 - val_accuracy: 0.9777 - val_loss: 0.0633\n",
      "Epoch 33/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 909us/step - accuracy: 0.9786 - loss: 0.0442 - val_accuracy: 0.9368 - val_loss: 0.1288\n",
      "Epoch 34/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 932us/step - accuracy: 0.9833 - loss: 0.0390 - val_accuracy: 0.9926 - val_loss: 0.0250\n",
      "Epoch 35/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 916us/step - accuracy: 0.9814 - loss: 0.0430 - val_accuracy: 0.9963 - val_loss: 0.0189\n",
      "Epoch 36/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 0.9851 - loss: 0.0349 - val_accuracy: 0.9888 - val_loss: 0.0247\n",
      "Epoch 37/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 920us/step - accuracy: 0.9814 - loss: 0.0411 - val_accuracy: 0.9851 - val_loss: 0.0358\n",
      "Epoch 38/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 978us/step - accuracy: 0.9758 - loss: 0.0431 - val_accuracy: 0.9888 - val_loss: 0.0240\n",
      "Epoch 39/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 0.9786 - loss: 0.0393 - val_accuracy: 0.9703 - val_loss: 0.0448\n",
      "Epoch 40/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - accuracy: 0.9861 - loss: 0.0329 - val_accuracy: 0.9814 - val_loss: 0.0503\n",
      "Epoch 41/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9814 - loss: 0.0363 - val_accuracy: 0.9851 - val_loss: 0.0312\n",
      "Epoch 42/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926us/step - accuracy: 0.9851 - loss: 0.0346 - val_accuracy: 0.9628 - val_loss: 0.0677\n",
      "Epoch 43/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 942us/step - accuracy: 0.9861 - loss: 0.0358 - val_accuracy: 0.9814 - val_loss: 0.0469\n",
      "Epoch 44/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 870us/step - accuracy: 0.9851 - loss: 0.0365 - val_accuracy: 0.9851 - val_loss: 0.0293\n",
      "Epoch 45/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 0.9814 - loss: 0.0372 - val_accuracy: 0.9963 - val_loss: 0.0160\n",
      "Epoch 46/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 862us/step - accuracy: 0.9823 - loss: 0.0383 - val_accuracy: 1.0000 - val_loss: 0.0161\n",
      "Epoch 47/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884us/step - accuracy: 0.9814 - loss: 0.0457 - val_accuracy: 0.9814 - val_loss: 0.0353\n",
      "Epoch 48/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - accuracy: 0.9786 - loss: 0.0476 - val_accuracy: 0.9926 - val_loss: 0.0203\n",
      "Epoch 49/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 0.9796 - loss: 0.0368 - val_accuracy: 0.9851 - val_loss: 0.0304\n",
      "Epoch 50/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 0.9805 - loss: 0.0410 - val_accuracy: 0.9963 - val_loss: 0.0154\n",
      "Epoch 51/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - accuracy: 0.9861 - loss: 0.0360 - val_accuracy: 0.9851 - val_loss: 0.0312\n",
      "Epoch 52/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 890us/step - accuracy: 0.9842 - loss: 0.0318 - val_accuracy: 0.9851 - val_loss: 0.0310\n",
      "Epoch 53/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9842 - loss: 0.0351 - val_accuracy: 0.9926 - val_loss: 0.0206\n",
      "Epoch 54/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 0.9805 - loss: 0.0398 - val_accuracy: 0.9777 - val_loss: 0.0417\n",
      "Epoch 55/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 930us/step - accuracy: 0.9823 - loss: 0.0399 - val_accuracy: 0.9963 - val_loss: 0.0165\n",
      "Epoch 56/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 917us/step - accuracy: 0.9879 - loss: 0.0320 - val_accuracy: 0.9926 - val_loss: 0.0171\n",
      "Epoch 57/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 904us/step - accuracy: 0.9879 - loss: 0.0268 - val_accuracy: 0.9926 - val_loss: 0.0185\n",
      "Epoch 58/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 957us/step - accuracy: 0.9842 - loss: 0.0372 - val_accuracy: 0.9554 - val_loss: 0.0936\n",
      "Epoch 59/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 0.9861 - loss: 0.0318 - val_accuracy: 0.9814 - val_loss: 0.0352\n",
      "Epoch 60/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9833 - loss: 0.0391 - val_accuracy: 0.9851 - val_loss: 0.0312\n",
      "Epoch 61/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 0.9823 - loss: 0.0337 - val_accuracy: 0.9703 - val_loss: 0.0491\n",
      "Epoch 62/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 951us/step - accuracy: 0.9823 - loss: 0.0349 - val_accuracy: 1.0000 - val_loss: 0.0139\n",
      "Epoch 63/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 930us/step - accuracy: 0.9870 - loss: 0.0302 - val_accuracy: 0.9963 - val_loss: 0.0135\n",
      "Epoch 64/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 0.9879 - loss: 0.0267 - val_accuracy: 0.9703 - val_loss: 0.0439\n",
      "Epoch 65/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 873us/step - accuracy: 0.9833 - loss: 0.0376 - val_accuracy: 1.0000 - val_loss: 0.0153\n",
      "Epoch 66/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - accuracy: 0.9879 - loss: 0.0334 - val_accuracy: 1.0000 - val_loss: 0.0131\n",
      "Epoch 67/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 961us/step - accuracy: 0.9823 - loss: 0.0365 - val_accuracy: 0.9888 - val_loss: 0.0273\n",
      "Epoch 68/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 0.9823 - loss: 0.0340 - val_accuracy: 0.9888 - val_loss: 0.0306\n",
      "Epoch 69/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 0.9870 - loss: 0.0296 - val_accuracy: 0.9851 - val_loss: 0.0266\n",
      "Epoch 70/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 0.9786 - loss: 0.0405 - val_accuracy: 0.9851 - val_loss: 0.0348\n",
      "Epoch 71/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 937us/step - accuracy: 0.9823 - loss: 0.0341 - val_accuracy: 0.9814 - val_loss: 0.0382\n",
      "Epoch 72/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 0.9786 - loss: 0.0444 - val_accuracy: 0.9665 - val_loss: 0.0586\n",
      "Epoch 73/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step - accuracy: 0.9861 - loss: 0.0315 - val_accuracy: 0.9851 - val_loss: 0.0317\n",
      "Epoch 74/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 0.9833 - loss: 0.0321 - val_accuracy: 0.9926 - val_loss: 0.0161\n",
      "Epoch 75/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 0.9861 - loss: 0.0272 - val_accuracy: 0.9851 - val_loss: 0.0307\n",
      "Epoch 76/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 927us/step - accuracy: 0.9888 - loss: 0.0240 - val_accuracy: 0.9963 - val_loss: 0.0131\n",
      "Epoch 77/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 912us/step - accuracy: 0.9861 - loss: 0.0334 - val_accuracy: 0.9777 - val_loss: 0.0339\n",
      "Epoch 78/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 966us/step - accuracy: 0.9786 - loss: 0.0384 - val_accuracy: 0.9740 - val_loss: 0.0409\n",
      "Epoch 79/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - accuracy: 0.9842 - loss: 0.0380 - val_accuracy: 0.9926 - val_loss: 0.0147\n",
      "Epoch 80/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 0.9888 - loss: 0.0269 - val_accuracy: 0.9851 - val_loss: 0.0256\n",
      "Epoch 81/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 0.9888 - loss: 0.0275 - val_accuracy: 0.9851 - val_loss: 0.0301\n",
      "Epoch 82/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 0.9805 - loss: 0.0353 - val_accuracy: 0.9963 - val_loss: 0.0135\n",
      "Epoch 83/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 891us/step - accuracy: 0.9879 - loss: 0.0301 - val_accuracy: 0.9926 - val_loss: 0.0165\n",
      "Epoch 84/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step - accuracy: 0.9870 - loss: 0.0301 - val_accuracy: 0.9888 - val_loss: 0.0237\n",
      "Epoch 85/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.9851 - loss: 0.0270 - val_accuracy: 0.9963 - val_loss: 0.0125\n",
      "Epoch 86/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 895us/step - accuracy: 0.9870 - loss: 0.0288 - val_accuracy: 0.9740 - val_loss: 0.0414\n",
      "Epoch 87/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 948us/step - accuracy: 0.9898 - loss: 0.0285 - val_accuracy: 0.9926 - val_loss: 0.0166\n",
      "Epoch 88/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 0.9907 - loss: 0.0245 - val_accuracy: 1.0000 - val_loss: 0.0120\n",
      "Epoch 89/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 0.9879 - loss: 0.0275 - val_accuracy: 0.9926 - val_loss: 0.0129\n",
      "Epoch 90/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.9833 - loss: 0.0366 - val_accuracy: 0.9851 - val_loss: 0.0329\n",
      "Epoch 91/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 886us/step - accuracy: 0.9814 - loss: 0.0329 - val_accuracy: 0.9926 - val_loss: 0.0170\n",
      "Epoch 92/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 0.9851 - loss: 0.0304 - val_accuracy: 0.9888 - val_loss: 0.0239\n",
      "Epoch 93/93\n",
      "\u001b[1m1076/1076\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 878us/step - accuracy: 0.9833 - loss: 0.0334 - val_accuracy: 0.9703 - val_loss: 0.0448\n"
     ]
    }
   ],
   "source": [
    "n = len(X_train)\n",
    "batch_size = 1\n",
    "steps_per_epoch = int(np.ceil(n / batch_size))\n",
    "target_steps = 100_000\n",
    "epochs_needed = int(np.ceil(target_steps / steps_per_epoch))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=epochs_needed,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eac48f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9703 - loss: 0.0448 \n",
      "Test accuracy: 0.970\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28bb2b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_color_class(model, rgb):\n",
    "    \"\"\"\n",
    "    Predicts whether a color should use a light or dark font.\n",
    "    \n",
    "    Parameters:\n",
    "        model: trained Keras model\n",
    "        rgb: list or array of [R, G, B] values (0–255)\n",
    "    \n",
    "    Returns:\n",
    "        \"hell\" if bright background (light font recommended)\n",
    "        \"dunkel\" if dark background (dark font recommended)\n",
    "    \"\"\"\n",
    "    sample = np.array(rgb).reshape(1, 3) / 255.0\n",
    "    pred = model.predict(sample, verbose=0)\n",
    "    return \"hell\" if pred > 0.5 else \"dunkel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdb5eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hell\n",
      "dunkel\n",
      "dunkel\n"
     ]
    }
   ],
   "source": [
    "print(predict_color_class(model, [255, 255, 255]))  # hell\n",
    "print(predict_color_class(model, [0, 0, 0]))        # dunkel\n",
    "print(predict_color_class(model, [120, 120, 120]))  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
